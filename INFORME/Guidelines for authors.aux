\relax 
\citation{A1}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Antecedentes trabajo de grado}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Planes de muestreo de aceptaci\'on de atributos mejorados basados en muestreo de nominaciones m\'aximas}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Planes de muestreo para numero de aceptaci\'on cero}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Efron \& Hastie (2017)}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Redes neuronales y aprendizaje profundo(cap 18)}{2}\protected@file@percent }
\citation{L}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Bosques aleatorios e impulso(cap 17)}{3}\protected@file@percent }
\citation{L}
\@writefile{toc}{\contentsline {section}{\numberline {3}Lantz (2013) o Torgo (2017)}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Aprendizaje probabil\IeC {\'\i }stico - clasificaci\'on usando bayes ingenuo(cap 4 - Lantz 2013)}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Divide y vencer\'as - Clasificaci\'on usando reglas y arboles de decisi\'on(cap 5 - Lantz 2013)}{4}\protected@file@percent }
\bibstyle{agsm}
\bibdata{references}
\harvardcite{EyH}{Efron \harvardand \ Hastie}{Efron \harvardand \ Hastie}{2017}
\harvardcite{A1}{Jozani \harvardand \ Mirkamali}{Jozani \harvardand \ Mirkamali}{2010}
\harvardcite{L}{Lantz}{Lantz}{2013}
\newlabel{@lastpage}{{3.2}{5}}
